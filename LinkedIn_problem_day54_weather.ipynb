{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPngW6w8plu7MMp8iHhxdW7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gangoliya/gangoliya/blob/main/LinkedIn_problem_day54_weather.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3gPmluzRqbm",
        "outputId": "7cb3d43b-0d26-4a51-f0a1-cb5c9345dc52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession"
      ],
      "metadata": {
        "id": "T1O7Qi9VRsXK"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName('Test').getOrCreate()"
      ],
      "metadata": {
        "id": "FXUgl-NiRw5Q"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
        "\n",
        "# Define the schema for the Weather DataFrame\n",
        "weather_schema = StructType([\n",
        "StructField(\"country_id\", IntegerType(), True),\n",
        "StructField(\"weather_state\", IntegerType(),\n",
        "True),\n",
        "StructField(\"day\", StringType(), True)\n",
        "])\n",
        "# Weather data\n",
        "weather_data = [\n",
        "(2, 15, \"2019-11-01\"),\n",
        "(2, 12, \"2019-10-28\"),\n",
        "(2, 12, \"2019-10-27\"),\n",
        "(3, -2, \"2019-11-10\"),\n",
        "(3, 0, \"2019-11-11\"),\n",
        "(3, 3, \"2019-11-12\"),\n",
        "(5, 16, \"2019-11-07\"),\n",
        "(5, 18, \"2019-11-09\"),\n",
        "(5, 21, \"2019-11-23\"),\n",
        "(7, 25, \"2019-11-28\"),\n",
        "(7, 22, \"2019-12-01\"),\n",
        "(7, 20, \"2019-12-02\"),\n",
        "(8, 25, \"2019-11-05\"),\n",
        "(8, 27, \"2019-11-15\"),\n",
        "(8, 31, \"2019-11-25\"),\n",
        "(9, 7, \"2019-10-23\"),\n",
        "(9, 3, \"2019-12-23\")\n",
        "]"
      ],
      "metadata": {
        "id": "0cZYVIH0R4ab"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the schema for the Countries DataFrame\n",
        "countries_schema = StructType([\n",
        "StructField(\"country_id\", IntegerType(), True),\n",
        "StructField(\"country_name\", StringType(), True)\n",
        "])\n",
        "countries_data = [\n",
        "(2, \"USA\"),\n",
        "(3, \"Australia\"),\n",
        "(7, \"Peru\"),\n",
        "(5, \"China\"),\n",
        "(8, \"Morocco\"),\n",
        "(9, \"Spain\")\n",
        "]"
      ],
      "metadata": {
        "id": "oqKK1_IJSILI"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_df = spark.createDataFrame(weather_data, weather_schema)\n",
        "weather_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhi7X7rISK0c",
        "outputId": "39027d52-ab00-4623-d7d2-71a1a9218258"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-------------+----------+\n",
            "|country_id|weather_state|       day|\n",
            "+----------+-------------+----------+\n",
            "|         2|           15|2019-11-01|\n",
            "|         2|           12|2019-10-28|\n",
            "|         2|           12|2019-10-27|\n",
            "|         3|           -2|2019-11-10|\n",
            "|         3|            0|2019-11-11|\n",
            "|         3|            3|2019-11-12|\n",
            "|         5|           16|2019-11-07|\n",
            "|         5|           18|2019-11-09|\n",
            "|         5|           21|2019-11-23|\n",
            "|         7|           25|2019-11-28|\n",
            "|         7|           22|2019-12-01|\n",
            "|         7|           20|2019-12-02|\n",
            "|         8|           25|2019-11-05|\n",
            "|         8|           27|2019-11-15|\n",
            "|         8|           31|2019-11-25|\n",
            "|         9|            7|2019-10-23|\n",
            "|         9|            3|2019-12-23|\n",
            "+----------+-------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "countries_df = spark.createDataFrame(countries_data, countries_schema)\n",
        "countries_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BffL-SbOSMm-",
        "outputId": "744674a1-4dee-4461-a1b6-6741a5581459"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------+\n",
            "|country_id|country_name|\n",
            "+----------+------------+\n",
            "|         2|         USA|\n",
            "|         3|   Australia|\n",
            "|         7|        Peru|\n",
            "|         5|       China|\n",
            "|         8|     Morocco|\n",
            "|         9|       Spain|\n",
            "+----------+------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_combined = countries_df.join(weather_df, on=\"country_id\")\n",
        "\n",
        "\n",
        "df_filtered = df_combined.filter((df_combined.day >= \"2019-11-01\")&(df_combined.day <= \"2019-11-30\"))"
      ],
      "metadata": {
        "id": "lHuarui1XOI5"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import avg\n",
        "df_groupped = df_filtered.groupBy(\"country_name\").agg(avg(\"weather_state\").alias(\"average\"))"
      ],
      "metadata": {
        "id": "D-5PXBwYUV7S"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "\n",
        "df_final = df_groupped.withColumn(\"weather_type\",when(df_groupped.average <= 15,\"COLD\")\\\n",
        "                                                  .when(df_groupped.average >= 25,\"HOT\")\\\n",
        "                                                  .otherwise(\"WARM\")\n",
        "                       ).select(\"country_name\",\"weather_type\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LtkS1pEdTWSw",
        "outputId": "67d0209d-05d8-4b64-bcd9-29da20b3dac3"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+------------+\n",
            "|country_name|weather_type|\n",
            "+------------+------------+\n",
            "|        Peru|         HOT|\n",
            "|       China|        WARM|\n",
            "|     Morocco|         HOT|\n",
            "|         USA|        COLD|\n",
            "|   Australia|        COLD|\n",
            "+------------+------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}